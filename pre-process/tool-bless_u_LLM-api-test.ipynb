{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzx_Pg6HxxfX"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxPjYiSLJcnV",
        "outputId": "a6e63619-9491-4d01-86cc-fed0cda76f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.2\n",
            "Collecting anthropic==0.40.0\n",
            "  Downloading anthropic-0.40.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.40.0) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic==0.40.0) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic==0.40.0) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic==0.40.0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic==0.40.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic==0.40.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic==0.40.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic==0.40.0) (2.27.1)\n",
            "Downloading anthropic-0.40.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.40.0\n",
            "Collecting openai==1.57.4\n",
            "  Downloading openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.57.4) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.57.4) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.57.4) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.57.4) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.57.4) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.57.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.57.4) (2.27.1)\n",
            "Downloading openai-1.57.4-py3-none-any.whl (390 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-1.57.4\n",
            "Collecting aisuite\n",
            "  Downloading aisuite-0.1.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading aisuite-0.1.6-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: aisuite\n",
            "Successfully installed aisuite-0.1.6\n",
            "time: 412 ¬µs (started: 2024-12-17 07:06:23 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%pip install ipython-autotime\n",
        "%pip install anthropic==0.40.0\n",
        "%pip install openai==1.57.4\n",
        "%pip install aisuite\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vB9qoqJseO",
        "outputId": "3e0d3f4e-0e8c-4a93-ac26-25b559ec2e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 437 ms (started: 2024-12-17 03:58:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqI0GZsCTAZ3"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFGWX2mjhXAR"
      },
      "source": [
        "## API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rnvgm1gTG75",
        "outputId": "b2930c8e-99d6-4b9e-fc6f-6e94ddfffd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.43 s (started: 2024-12-17 07:07:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Set your sensitive API_KEY via colab > secrets > add key\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('open_ai_key_nycu')\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "\n",
        "TEMPERATURE = 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KlyHFeebr_A"
      },
      "source": [
        "## openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOaDKpUYbaVc",
        "outputId": "de9f16e7-98de-4e1d-a579-f68c52fa0b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gpt-4o-mini Why did the pirate go to school? \n",
            "\n",
            "To improve his \"arrrrrticulation!\" Har har har!\n",
            "time: 2.72 s (started: 2024-12-17 04:01:36 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import typing\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_model = 'gpt-4o-mini'\n",
        "openai_client = OpenAI(\n",
        "    api_key=os.environ.get('OPENAI_API_KEY'),\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
        "]\n",
        "\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=openai_model,\n",
        "    messages=messages,\n",
        "    temperature=TEMPERATURE\n",
        ")\n",
        "print(openai_model, response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDERc2bWb_Dx"
      },
      "source": [
        "## anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GHjP_GAcA9B",
        "outputId": "c6bd4212-deec-4bb5-9bb3-6c2de05989ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "claude-3-opus-20240229 Hello! It's nice to meet you. How can I assist you today?\n",
            "time: 1.19 s (started: 2024-12-17 04:01:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from anthropic import Anthropic\n",
        "\n",
        "anthropic_model = 'claude-3-opus-20240229'\n",
        "DEFAULT_TOKENS = 512\n",
        "\n",
        "anthropic_client = Anthropic(\n",
        "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
        ")\n",
        "\n",
        "message = anthropic_client.messages.create(\n",
        "    max_tokens=512,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello, Claude\",\n",
        "        }\n",
        "    ],\n",
        "    model=anthropic_model,\n",
        "    temperature=TEMPERATURE,\n",
        ")\n",
        "print(anthropic_model, message.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EXVPqfPhRf3"
      },
      "source": [
        "## aisuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkUyluIFTGx0",
        "outputId": "24c9ae1e-1771-4db1-a983-913f03f3f746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anthropic:claude-3-5-sonnet-20241022 Yarr! Here be a joke fer ye, matey!\n",
            "\n",
            "Why don't pirates shower before they walk the plank?\n",
            "\n",
            "Because they'll just wash up on shore later! HARR HARR HARR! \n",
            "\n",
            "*slaps knee with me wooden leg*\n",
            "\n",
            "If ye didn't find that funny, ye can feed me to the sharks, ye scurvy dog! üè¥‚Äç‚ò†Ô∏è\n",
            "time: 3.55 s (started: 2024-12-17 07:07:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import aisuite as ai\n",
        "client = ai.Client()\n",
        "\n",
        "# models = [\"openai:gpt-4o-mini\"] #, \"anthropic:claude-3-5-sonnet-20240620\"]\n",
        "models = [\"anthropic:claude-3-5-sonnet-20241022\"]\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=TEMPERATURE\n",
        "    )\n",
        "    print(model, response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
